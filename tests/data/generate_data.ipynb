{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit test data\n",
    "\n",
    "This directory contains very small, toy, data sets that are used\n",
    "for unit tests.\n",
    "\n",
    "## Object catalog: small_sky\n",
    "\n",
    "This \"object catalog\" is 131 randomly generated radec values. \n",
    "\n",
    "- All radec positions are in the Healpix pixel order 0, pixel 11.\n",
    "- IDs are integers from 700-831."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hipscat_import.pipeline as runner\n",
    "from hipscat_import.catalog.arguments import ImportArguments\n",
    "from hipscat_import.index.arguments import IndexArguments\n",
    "from hipscat_import.margin_cache.margin_cache_arguments import MarginCacheArguments\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "tmp_path = tempfile.TemporaryDirectory()\n",
    "tmp_dir = tmp_path.name\n",
    "\n",
    "hipscat_import_dir = \"../../../hipscat-import/tests/hipscat_import/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky\n",
    "\n",
    "This \"object catalog\" is 131 randomly generated radec values. \n",
    "\n",
    "- All radec positions are in the Healpix pixel order 0, pixel 11.\n",
    "- IDs are integers from 700-831.\n",
    "\n",
    "This catalog was generated with the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    input_path=Path(hipscat_import_dir)/\"small_sky\",\n",
    "    output_path=\".\",\n",
    "    file_reader=\"csv\",\n",
    "    output_artifact_name=\"small_sky\",\n",
    "    overwrite=True,\n",
    "    tmp_dir=tmp_dir,\n",
    ")\n",
    "runner.pipeline(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order1\n",
    "\n",
    "This catalog has the same data points as other small sky catalogs,\n",
    "but is coerced to spreading these data points over partitions at order 1, instead\n",
    "of order 0.\n",
    "\n",
    "This means there are 4 leaf partition files, instead of just 1, and so can\n",
    "be useful for confirming reads/writes over multiple leaf partition files.\n",
    "\n",
    "NB: Setting `constant_healpix_order` coerces the import pipeline to create\n",
    "leaf partitions at order 1.\n",
    "\n",
    "This catalog was generated with the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    input_path=Path(hipscat_import_dir)/\"small_sky\",\n",
    "    output_path=\".\",\n",
    "    file_reader=\"csv\",\n",
    "    output_artifact_name=\"small_sky_order1\",\n",
    "    constant_healpix_order=1,\n",
    "    overwrite=True,\n",
    "    tmp_dir=tmp_dir,\n",
    ")\n",
    "runner.pipeline(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order1_id_index\n",
    "\n",
    "An index table (that is NOT a \"true\" hipscat catalog) to map the \"id\" field to the partition the row can be found in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = IndexArguments(\n",
    "    input_catalog_path=\"small_sky\",\n",
    "    indexing_column=\"id\",\n",
    "    output_path=\".\",\n",
    "    output_artifact_name=\"small_sky_order1_id_index\",\n",
    "    include_hipscat_index=False,\n",
    "    compute_partition_size=200_000,\n",
    "    overwrite=True,\n",
    "    tmp_dir=tmp_dir,\n",
    ")\n",
    "runner.pipeline(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_order1_margin\n",
    "\n",
    "This catalog exists as an margin cache of the small_sky_order1 table,\n",
    "allowing spatial operations to be performed efficiently and accurately.\n",
    "\n",
    "NB: \n",
    "\n",
    "- The setting `margin_threshold` at 7200 arcseconds (2 degrees) is much higher than\n",
    "  a usual margin cache would be generated at, but is used because the small sky test\n",
    "  dataset is sparse.\n",
    "- The `small_sky_order1` catalog only contains points in Norder1, Npix=[44, 45, 46, 47], but the margin catalog also contains points in Norder0, Npix=4 due to negative pixel margins.\n",
    "\n",
    "\n",
    "This catalog was generated using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_args = MarginCacheArguments(\n",
    "    margin_threshold=7200,\n",
    "    input_catalog_path=\"small_sky_order1\",\n",
    "    output_path=\".\",\n",
    "    output_artifact_name=\"small_sky_order1_margin\",\n",
    "    overwrite=True,\n",
    "    tmp_dir=tmp_dir,\n",
    ")\n",
    "runner.pipeline(margin_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_to_small_sky_order1\n",
    "\n",
    "Association table that maps (pretty naively) the `small_sky` to `small_sky_order1`. Note that these are the *same* catalog data, but the stored pixels are at different healpix orders.\n",
    "\n",
    "Note also that this doesn't really create a catalog! This is faking out a \"soft\" association catalog, which just contains the partition join information, and not the actual matching rows. It's not generated by any \"import pipeline\", but just through writing the files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hipscat.catalog.association_catalog.partition_join_info import PartitionJoinInfo\n",
    "\n",
    "join_pixels= pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Norder\": [0, 0, 0, 0],\n",
    "        \"Npix\": [11, 11, 11, 11],\n",
    "        \"join_Norder\": [1, 1, 1, 1],\n",
    "        \"join_Npix\": [44, 45, 46, 47],\n",
    "    }\n",
    ")\n",
    "join_info = PartitionJoinInfo(join_pixels, catalog_base_dir=\"small_sky_to_small_sky_order1\")\n",
    "join_info.write_to_csv()\n",
    "join_info.write_to_metadata_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source catalog: small_sky_source\n",
    "\n",
    "This \"source catalog\" is 131 detections at each of the 131 objects\n",
    "in the \"small_sky\" catalog. These have a random magnitude, MJD, and \n",
    "band (selected from ugrizy). The full script that generated the values\n",
    "can be found [here](https://github.com/delucchi-cmu/hipscripts/blob/main/twiddling/small_sky_source.py)\n",
    "\n",
    "The catalog was generated with the following snippet, using raw data \n",
    "from the `hipscat-import` file.\n",
    "\n",
    "NB: `pixel_threshold=3000` is set just to make sure that we're generating\n",
    "a handful of files at various healpix orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    input_path=Path(hipscat_import_dir)/\"small_sky_source\",\n",
    "    output_path=\".\",\n",
    "    file_reader=\"csv\",\n",
    "    ra_column=\"source_ra\",\n",
    "    dec_column=\"source_dec\",\n",
    "    catalog_type= \"source\",\n",
    "    pixel_threshold= 3000,\n",
    "    output_artifact_name=\"small_sky_source\",\n",
    "    overwrite=True,\n",
    "    tmp_dir=tmp_dir,\n",
    ")\n",
    "runner.pipeline(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small_sky_source_object_index\n",
    "\n",
    "This catalog exists as an index of the SOURCE table, using the OBJECT ID\n",
    "as the indexed column. This means you should be able to quickly find\n",
    "partions of SOURCES for a given OBJECT ID.\n",
    "\n",
    "NB: \n",
    "\n",
    "- Setting `compute_partition_size` to something less than `1_000_000` \n",
    "  coerces the import pipeline to create smaller result partitions, \n",
    "  and so we have three distinct index partitions.\n",
    "- Setting `include_hipscat_index=False` keeps us from needing a row for every \n",
    "  source and lets the indexing pipeline create only one row per \n",
    "  unique objectId/Norder/Npix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = IndexArguments(\n",
    "    input_catalog_path=\"small_sky_source\",\n",
    "    indexing_column=\"object_id\",\n",
    "    output_path=\".\",\n",
    "    output_artifact_name=\"small_sky_source_object_index\",\n",
    "    include_hipscat_index=False,\n",
    "    compute_partition_size=200_000,\n",
    "    overwrite=True,\n",
    "    tmp_dir=tmp_dir,\n",
    ")\n",
    "runner.pipeline(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipscatenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
